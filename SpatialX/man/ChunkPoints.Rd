% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utilties.R
\name{ChunkPoints}
\alias{ChunkPoints}
\title{Generate chunk points for data processing}
\usage{
ChunkPoints(dsize, csize)
}
\arguments{
\item{dsize}{Total size of the data to be chunked (number of elements)}

\item{csize}{Size of each chunk. If \code{NA}, assumes a single chunk
covering the entire dataset}
}
\value{
A matrix with two columns where each row represents a chunk:
  \itemize{
    \item Column 1: Start index of the chunk
    \item Column 2: End index of the chunk
  }
  The matrix has as many rows as there are chunks.
}
\description{
This internal function generates start and end points for chunking large
datasets into manageable pieces for parallel processing or memory-efficient
computation. It is particularly useful for processing large matrices or
data frames in batches.
}
\details{
This function is used internally to break down large computational tasks
into smaller chunks for:
\itemize{
  \item Parallel processing across multiple cores
  \item Memory-efficient batch processing of large datasets
  \item Progress tracking in iterative operations
  \item Error handling in partial computations
}

The function ensures that:
\itemize{
  \item All data points are covered without gaps
  \item Chunks are as evenly sized as possible
  \item The last chunk handles any remainder
  \item Single-chunk case is handled efficiently
}
}
\examples{
\dontrun{
# Chunk 100 elements into groups of 25
chunks <- ChunkPoints(100, 25)
print(chunks)
#      start end
# [1,]     1  25
# [2,]    26  50
# [3,]    51  75
# [4,]    76 100

# Single chunk case
single_chunk <- ChunkPoints(50, NA)
print(single_chunk)
#      start end
# [1,]     1  50

# Chunk with remainder
remainder_chunks <- ChunkPoints(23, 10)
print(remainder_chunks)
#      start end
# [1,]     1  10
# [2,]    11  20
# [3,]    21  23

# Use in parallel processing
chunks <- ChunkPoints(nrow(large_matrix), 1000)
results <- parallel::mclapply(1:nrow(chunks), function(i) {
  chunk <- large_matrix[chunks[i, 1]:chunks[i, 2], ]
  process_chunk(chunk)
}, mc.cores = 4)
}


}
\keyword{internal}
