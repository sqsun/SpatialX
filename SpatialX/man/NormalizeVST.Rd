% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utilties.R
\name{NormalizeVST}
\alias{NormalizeVST}
\alias{NormalizeVSTfast}
\title{Anscombe variance stabilizing transformation for negative binomial data}
\usage{
NormalizeVST(counts, sv = 1)

NormalizeVSTfast(counts, sv = 1)
}
\arguments{
\item{counts}{A gene expression count matrix with features (genes) as rows
and samples (cells/spots) as columns. Should contain
non-negative integer counts.}

\item{sv}{Normalization parameter used as starting value for estimating
the dispersion parameter phi. Default is 1.}
}
\value{
Returns a matrix of variance-stabilized and normalized expression
        values with the same dimensions as the input counts matrix. The
        values are on a continuous scale with stabilized variance.
}
\description{
These functions perform Anscombe's variance stabilizing transformation on
count data following a negative binomial distribution. The transformation
stabilizes the variance across different expression levels, making the data
more suitable for downstream statistical analyses that assume homoscedasticity.
}
\details{
The Anscombe transformation for negative binomial data is defined as:
\deqn{\log\left(\frac{counts + \frac{1}{2\phi}}{total}\right)}
where \eqn{\phi} is the dispersion parameter estimated from the data.

The transformation consists of two main steps:
\enumerate{
  \item Estimate the dispersion parameter \eqn{\phi} by fitting the
        relationship: \eqn{Var(X) = \mu + \phi \mu^2}
  \item Apply the variance stabilizing transformation and regress out
        library size effects
}

This approach is particularly useful for:
\itemize{
  \item Preparing count data for methods assuming homoscedastic variance
  \item Reducing the influence of extreme values in highly variable genes
  \item Improving performance of clustering and dimensionality reduction
  \item Enabling the use of Euclidean distance-based methods
}
}
\section{Functions}{

\describe{
  \item{\code{NormalizeVST}}{Standard implementation using base R functions
        for variance and mean calculation. Suitable for small to medium datasets.}
  \item{\code{NormalizeVSTfast}}{Optimized implementation using Rcpp functions
        for efficient computation of row means, variances, and sums. Recommended
        for large datasets.}
}
}

\examples{
\dontrun{
# Generate example count data
set.seed(123)
counts <- matrix(rnbinom(1000, size = 2, mu = 10), nrow = 100, ncol = 10)

# Apply variance stabilizing transformation
vst_data <- NormalizeVST(counts)

# Check variance stabilization
original_vars <- apply(counts, 1, var)
transformed_vars <- apply(vst_data, 1, var)

# Compare variance distributions
summary(original_vars)
summary(transformed_vars)

# Use fast version for large datasets
vst_data_fast <- NormalizeVSTfast(counts)

# Use in downstream analysis
pca_result <- prcomp(t(vst_data), scale. = TRUE)
}

}
\references{
Anscombe, F. J. (1948). The transformation of Poisson, binomial and
negative-binomial data. Biometrika, 35(3/4), 246-254.
}
